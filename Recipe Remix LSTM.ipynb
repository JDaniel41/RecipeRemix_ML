{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = 128\n",
    "        self.embedding_dim = 128\n",
    "        self.num_layers = 3\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df\n",
    "    ):\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def load_words(self):\n",
    "        text = train_df.str.cat(sep=' ')\n",
    "        return text.split(' ')\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - 4\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+4]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+4+1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model, results_list, batch=256, max_epochs=10, sequence_length=4):\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        state_h, state_c = model.init_state(sequence_length)\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
    "            results_list.append([epoch, batch, loss.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model, text, next_words=100):\n",
    "    model.eval()\n",
    "\n",
    "    words = text.split(' ')\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmdanie/Documents/Code/Hackathons/Bon-Hacketit/venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/RAW_recipes.csv')\n",
    "recipe_df = df[[\"steps\"]]\n",
    "\n",
    "recipe_df[\"processed\"] = [\". \".join(ast.literal_eval(step_array)) for step_array in recipe_df.steps]\n",
    "\n",
    "train_df, test_df = train_test_split(recipe_df[\"processed\"], train_size=.8, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 0, 'loss': 11.2608060836792}\n",
      "{'epoch': 0, 'batch': 1, 'loss': 11.245948791503906}\n",
      "{'epoch': 0, 'batch': 2, 'loss': 11.238430976867676}\n",
      "{'epoch': 0, 'batch': 3, 'loss': 11.228371620178223}\n",
      "{'epoch': 0, 'batch': 4, 'loss': 11.220096588134766}\n",
      "{'epoch': 0, 'batch': 5, 'loss': 11.21103286743164}\n",
      "{'epoch': 0, 'batch': 6, 'loss': 11.186309814453125}\n",
      "{'epoch': 0, 'batch': 7, 'loss': 11.159743309020996}\n",
      "{'epoch': 0, 'batch': 8, 'loss': 11.09915542602539}\n",
      "{'epoch': 0, 'batch': 9, 'loss': 10.991277694702148}\n",
      "{'epoch': 0, 'batch': 10, 'loss': 10.905417442321777}\n",
      "{'epoch': 0, 'batch': 11, 'loss': 10.700589179992676}\n",
      "{'epoch': 0, 'batch': 12, 'loss': 10.531011581420898}\n",
      "{'epoch': 0, 'batch': 13, 'loss': 10.078740119934082}\n",
      "{'epoch': 0, 'batch': 14, 'loss': 9.9773530960083}\n",
      "{'epoch': 0, 'batch': 15, 'loss': 9.875476837158203}\n",
      "{'epoch': 0, 'batch': 16, 'loss': 9.75689697265625}\n",
      "{'epoch': 0, 'batch': 17, 'loss': 9.167888641357422}\n",
      "{'epoch': 0, 'batch': 18, 'loss': 9.040729522705078}\n",
      "{'epoch': 0, 'batch': 19, 'loss': 8.677518844604492}\n",
      "{'epoch': 0, 'batch': 20, 'loss': 8.59524917602539}\n",
      "{'epoch': 0, 'batch': 21, 'loss': 8.671929359436035}\n",
      "{'epoch': 0, 'batch': 22, 'loss': 8.257485389709473}\n",
      "{'epoch': 0, 'batch': 23, 'loss': 8.246479034423828}\n",
      "{'epoch': 0, 'batch': 24, 'loss': 8.1952543258667}\n",
      "{'epoch': 0, 'batch': 25, 'loss': 7.8987579345703125}\n",
      "{'epoch': 0, 'batch': 26, 'loss': 7.555644989013672}\n",
      "{'epoch': 0, 'batch': 27, 'loss': 7.32890510559082}\n",
      "{'epoch': 0, 'batch': 28, 'loss': 7.328257083892822}\n",
      "{'epoch': 0, 'batch': 29, 'loss': 6.9380574226379395}\n",
      "{'epoch': 0, 'batch': 30, 'loss': 6.954320430755615}\n",
      "{'epoch': 0, 'batch': 31, 'loss': 6.756946563720703}\n",
      "{'epoch': 0, 'batch': 32, 'loss': 7.078275680541992}\n",
      "{'epoch': 0, 'batch': 33, 'loss': 6.776833534240723}\n",
      "{'epoch': 0, 'batch': 34, 'loss': 6.513321399688721}\n",
      "{'epoch': 0, 'batch': 35, 'loss': 6.886292457580566}\n",
      "{'epoch': 0, 'batch': 36, 'loss': 6.40443229675293}\n",
      "{'epoch': 0, 'batch': 37, 'loss': 6.360259056091309}\n",
      "{'epoch': 0, 'batch': 38, 'loss': 6.497679710388184}\n",
      "{'epoch': 0, 'batch': 39, 'loss': 6.733245372772217}\n",
      "{'epoch': 0, 'batch': 40, 'loss': 6.869255065917969}\n",
      "{'epoch': 0, 'batch': 41, 'loss': 6.154324531555176}\n",
      "{'epoch': 0, 'batch': 42, 'loss': 6.617818832397461}\n",
      "{'epoch': 0, 'batch': 43, 'loss': 7.198751926422119}\n",
      "{'epoch': 0, 'batch': 44, 'loss': 6.679017066955566}\n",
      "{'epoch': 0, 'batch': 45, 'loss': 6.6092658042907715}\n",
      "{'epoch': 0, 'batch': 46, 'loss': 6.901169300079346}\n",
      "{'epoch': 0, 'batch': 47, 'loss': 6.585048198699951}\n",
      "{'epoch': 0, 'batch': 48, 'loss': 6.890795707702637}\n",
      "{'epoch': 0, 'batch': 49, 'loss': 6.569545269012451}\n",
      "{'epoch': 0, 'batch': 50, 'loss': 6.54067850112915}\n",
      "{'epoch': 0, 'batch': 51, 'loss': 6.591700553894043}\n",
      "{'epoch': 0, 'batch': 52, 'loss': 6.142585277557373}\n",
      "{'epoch': 0, 'batch': 53, 'loss': 6.685206890106201}\n",
      "{'epoch': 0, 'batch': 54, 'loss': 6.166106224060059}\n",
      "{'epoch': 0, 'batch': 55, 'loss': 7.203370094299316}\n",
      "{'epoch': 0, 'batch': 56, 'loss': 6.2337727546691895}\n",
      "{'epoch': 0, 'batch': 57, 'loss': 6.400960445404053}\n",
      "{'epoch': 0, 'batch': 58, 'loss': 5.9427809715271}\n",
      "{'epoch': 0, 'batch': 59, 'loss': 6.534192085266113}\n",
      "{'epoch': 0, 'batch': 60, 'loss': 6.22179651260376}\n",
      "{'epoch': 0, 'batch': 61, 'loss': 6.584603786468506}\n",
      "{'epoch': 0, 'batch': 62, 'loss': 5.804776191711426}\n",
      "{'epoch': 0, 'batch': 63, 'loss': 6.057186126708984}\n",
      "{'epoch': 0, 'batch': 64, 'loss': 6.942756175994873}\n",
      "{'epoch': 0, 'batch': 65, 'loss': 6.249351501464844}\n",
      "{'epoch': 0, 'batch': 66, 'loss': 7.040826797485352}\n",
      "{'epoch': 0, 'batch': 67, 'loss': 7.374591827392578}\n",
      "{'epoch': 0, 'batch': 68, 'loss': 6.914686679840088}\n",
      "{'epoch': 0, 'batch': 69, 'loss': 6.6709675788879395}\n",
      "{'epoch': 0, 'batch': 70, 'loss': 6.884469985961914}\n",
      "{'epoch': 0, 'batch': 71, 'loss': 6.549324989318848}\n",
      "{'epoch': 0, 'batch': 72, 'loss': 6.151456832885742}\n",
      "{'epoch': 0, 'batch': 73, 'loss': 6.455440044403076}\n",
      "{'epoch': 0, 'batch': 74, 'loss': 6.7502312660217285}\n",
      "{'epoch': 0, 'batch': 75, 'loss': 7.047271728515625}\n",
      "{'epoch': 0, 'batch': 76, 'loss': 6.447277545928955}\n",
      "{'epoch': 0, 'batch': 77, 'loss': 6.447521209716797}\n",
      "{'epoch': 0, 'batch': 78, 'loss': 6.459517478942871}\n",
      "{'epoch': 0, 'batch': 79, 'loss': 6.639111518859863}\n",
      "{'epoch': 0, 'batch': 80, 'loss': 7.048248767852783}\n",
      "{'epoch': 0, 'batch': 81, 'loss': 6.887943744659424}\n",
      "{'epoch': 0, 'batch': 82, 'loss': 6.712689399719238}\n",
      "{'epoch': 0, 'batch': 83, 'loss': 6.1740546226501465}\n",
      "{'epoch': 0, 'batch': 84, 'loss': 6.635599136352539}\n",
      "{'epoch': 0, 'batch': 85, 'loss': 6.550079345703125}\n",
      "{'epoch': 0, 'batch': 86, 'loss': 6.312734127044678}\n",
      "{'epoch': 0, 'batch': 87, 'loss': 6.8040924072265625}\n",
      "{'epoch': 0, 'batch': 88, 'loss': 6.903202056884766}\n",
      "{'epoch': 0, 'batch': 89, 'loss': 7.227901458740234}\n",
      "{'epoch': 0, 'batch': 90, 'loss': 6.804052829742432}\n",
      "{'epoch': 0, 'batch': 91, 'loss': 7.08322286605835}\n",
      "{'epoch': 0, 'batch': 92, 'loss': 6.818137168884277}\n",
      "{'epoch': 0, 'batch': 93, 'loss': 6.528102874755859}\n",
      "{'epoch': 0, 'batch': 94, 'loss': 6.45957612991333}\n",
      "{'epoch': 0, 'batch': 95, 'loss': 5.88327693939209}\n",
      "{'epoch': 0, 'batch': 96, 'loss': 6.085707664489746}\n",
      "{'epoch': 0, 'batch': 97, 'loss': 6.360165596008301}\n",
      "{'epoch': 0, 'batch': 98, 'loss': 6.7787885665893555}\n",
      "{'epoch': 0, 'batch': 99, 'loss': 6.470396518707275}\n",
      "{'epoch': 0, 'batch': 100, 'loss': 6.583835601806641}\n",
      "{'epoch': 0, 'batch': 101, 'loss': 6.970088481903076}\n",
      "{'epoch': 0, 'batch': 102, 'loss': 5.913028240203857}\n",
      "{'epoch': 0, 'batch': 103, 'loss': 6.743819236755371}\n",
      "{'epoch': 0, 'batch': 104, 'loss': 6.729850769042969}\n",
      "{'epoch': 0, 'batch': 105, 'loss': 6.121135234832764}\n",
      "{'epoch': 0, 'batch': 106, 'loss': 6.002264499664307}\n",
      "{'epoch': 0, 'batch': 107, 'loss': 6.421253681182861}\n",
      "{'epoch': 0, 'batch': 108, 'loss': 6.237216949462891}\n",
      "{'epoch': 0, 'batch': 109, 'loss': 6.856751918792725}\n",
      "{'epoch': 0, 'batch': 110, 'loss': 5.659985065460205}\n",
      "{'epoch': 0, 'batch': 111, 'loss': 6.5316267013549805}\n",
      "{'epoch': 0, 'batch': 112, 'loss': 6.2037200927734375}\n",
      "{'epoch': 0, 'batch': 113, 'loss': 7.636747360229492}\n",
      "{'epoch': 0, 'batch': 114, 'loss': 6.055609226226807}\n",
      "{'epoch': 0, 'batch': 115, 'loss': 6.456725597381592}\n",
      "{'epoch': 0, 'batch': 116, 'loss': 6.079295635223389}\n",
      "{'epoch': 0, 'batch': 117, 'loss': 6.680803298950195}\n",
      "{'epoch': 0, 'batch': 118, 'loss': 6.306148052215576}\n",
      "{'epoch': 0, 'batch': 119, 'loss': 6.37033748626709}\n",
      "{'epoch': 0, 'batch': 120, 'loss': 6.3131608963012695}\n",
      "{'epoch': 0, 'batch': 121, 'loss': 6.420617580413818}\n",
      "{'epoch': 0, 'batch': 122, 'loss': 6.788661956787109}\n",
      "{'epoch': 0, 'batch': 123, 'loss': 6.854825496673584}\n",
      "{'epoch': 0, 'batch': 124, 'loss': 6.678644180297852}\n",
      "{'epoch': 0, 'batch': 125, 'loss': 6.476491451263428}\n",
      "{'epoch': 0, 'batch': 126, 'loss': 6.536665439605713}\n",
      "{'epoch': 0, 'batch': 127, 'loss': 6.582146644592285}\n",
      "{'epoch': 0, 'batch': 128, 'loss': 6.236808776855469}\n",
      "{'epoch': 0, 'batch': 129, 'loss': 5.899192810058594}\n",
      "{'epoch': 0, 'batch': 130, 'loss': 6.742186546325684}\n",
      "{'epoch': 0, 'batch': 131, 'loss': 6.116200923919678}\n",
      "{'epoch': 0, 'batch': 132, 'loss': 6.382477760314941}\n",
      "{'epoch': 0, 'batch': 133, 'loss': 6.063175678253174}\n",
      "{'epoch': 0, 'batch': 134, 'loss': 6.505949974060059}\n",
      "{'epoch': 0, 'batch': 135, 'loss': 6.312785625457764}\n",
      "{'epoch': 0, 'batch': 136, 'loss': 6.02561092376709}\n",
      "{'epoch': 0, 'batch': 137, 'loss': 6.612653732299805}\n",
      "{'epoch': 0, 'batch': 138, 'loss': 6.703799247741699}\n",
      "{'epoch': 0, 'batch': 139, 'loss': 6.336568832397461}\n",
      "{'epoch': 0, 'batch': 140, 'loss': 6.867837905883789}\n",
      "{'epoch': 0, 'batch': 141, 'loss': 6.5441179275512695}\n",
      "{'epoch': 0, 'batch': 142, 'loss': 6.015648365020752}\n",
      "{'epoch': 0, 'batch': 143, 'loss': 6.6875715255737305}\n",
      "{'epoch': 0, 'batch': 144, 'loss': 6.630508899688721}\n",
      "{'epoch': 0, 'batch': 145, 'loss': 6.576070785522461}\n",
      "{'epoch': 0, 'batch': 146, 'loss': 6.439610958099365}\n",
      "{'epoch': 0, 'batch': 147, 'loss': 5.919277667999268}\n",
      "{'epoch': 0, 'batch': 148, 'loss': 7.146726131439209}\n",
      "{'epoch': 0, 'batch': 149, 'loss': 6.574656009674072}\n",
      "{'epoch': 0, 'batch': 150, 'loss': 6.318383693695068}\n",
      "{'epoch': 0, 'batch': 151, 'loss': 6.4653801918029785}\n",
      "{'epoch': 0, 'batch': 152, 'loss': 6.492230415344238}\n",
      "{'epoch': 0, 'batch': 153, 'loss': 6.06553840637207}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 154, 'loss': 7.071927547454834}\n",
      "{'epoch': 0, 'batch': 155, 'loss': 6.83410120010376}\n",
      "{'epoch': 0, 'batch': 156, 'loss': 6.762159824371338}\n",
      "{'epoch': 0, 'batch': 157, 'loss': 6.286306858062744}\n",
      "{'epoch': 0, 'batch': 158, 'loss': 6.357349872589111}\n",
      "{'epoch': 0, 'batch': 159, 'loss': 7.04067325592041}\n",
      "{'epoch': 0, 'batch': 160, 'loss': 6.353498458862305}\n",
      "{'epoch': 0, 'batch': 161, 'loss': 6.203556060791016}\n",
      "{'epoch': 0, 'batch': 162, 'loss': 6.457461833953857}\n",
      "{'epoch': 0, 'batch': 163, 'loss': 6.3608527183532715}\n",
      "{'epoch': 0, 'batch': 164, 'loss': 6.285211086273193}\n",
      "{'epoch': 0, 'batch': 165, 'loss': 6.271991729736328}\n",
      "{'epoch': 0, 'batch': 166, 'loss': 5.985750675201416}\n",
      "{'epoch': 0, 'batch': 167, 'loss': 6.873164653778076}\n",
      "{'epoch': 0, 'batch': 168, 'loss': 6.220191955566406}\n",
      "{'epoch': 0, 'batch': 169, 'loss': 6.192991733551025}\n",
      "{'epoch': 0, 'batch': 170, 'loss': 6.229339599609375}\n",
      "{'epoch': 0, 'batch': 171, 'loss': 6.6522016525268555}\n",
      "{'epoch': 0, 'batch': 172, 'loss': 6.622620582580566}\n",
      "{'epoch': 0, 'batch': 173, 'loss': 6.378179550170898}\n",
      "{'epoch': 0, 'batch': 174, 'loss': 6.614381313323975}\n",
      "{'epoch': 0, 'batch': 175, 'loss': 6.490078449249268}\n",
      "{'epoch': 0, 'batch': 176, 'loss': 6.372523307800293}\n",
      "{'epoch': 0, 'batch': 177, 'loss': 6.244050025939941}\n",
      "{'epoch': 0, 'batch': 178, 'loss': 6.280965805053711}\n",
      "{'epoch': 0, 'batch': 179, 'loss': 6.510973930358887}\n",
      "{'epoch': 0, 'batch': 180, 'loss': 6.83495569229126}\n",
      "{'epoch': 0, 'batch': 181, 'loss': 6.478822708129883}\n",
      "{'epoch': 0, 'batch': 182, 'loss': 6.080934524536133}\n",
      "{'epoch': 0, 'batch': 183, 'loss': 6.873327255249023}\n",
      "{'epoch': 0, 'batch': 184, 'loss': 6.342363357543945}\n",
      "{'epoch': 0, 'batch': 185, 'loss': 6.338390350341797}\n",
      "{'epoch': 0, 'batch': 186, 'loss': 6.665463447570801}\n",
      "{'epoch': 0, 'batch': 187, 'loss': 6.197322368621826}\n",
      "{'epoch': 0, 'batch': 188, 'loss': 6.179137229919434}\n",
      "{'epoch': 0, 'batch': 189, 'loss': 5.892125606536865}\n",
      "{'epoch': 0, 'batch': 190, 'loss': 6.010815143585205}\n",
      "{'epoch': 0, 'batch': 191, 'loss': 6.4058003425598145}\n",
      "{'epoch': 0, 'batch': 192, 'loss': 6.606934547424316}\n",
      "{'epoch': 0, 'batch': 193, 'loss': 6.513627052307129}\n",
      "{'epoch': 0, 'batch': 194, 'loss': 6.853564739227295}\n",
      "{'epoch': 0, 'batch': 195, 'loss': 6.448269844055176}\n",
      "{'epoch': 0, 'batch': 196, 'loss': 6.625332355499268}\n",
      "{'epoch': 0, 'batch': 197, 'loss': 6.522214412689209}\n",
      "{'epoch': 0, 'batch': 198, 'loss': 6.6035637855529785}\n",
      "{'epoch': 0, 'batch': 199, 'loss': 6.0888752937316895}\n",
      "{'epoch': 0, 'batch': 200, 'loss': 6.456398010253906}\n",
      "{'epoch': 0, 'batch': 201, 'loss': 6.109858989715576}\n",
      "{'epoch': 0, 'batch': 202, 'loss': 6.2552924156188965}\n",
      "{'epoch': 0, 'batch': 203, 'loss': 6.810441493988037}\n",
      "{'epoch': 0, 'batch': 204, 'loss': 6.491650104522705}\n",
      "{'epoch': 0, 'batch': 205, 'loss': 6.589087009429932}\n",
      "{'epoch': 0, 'batch': 206, 'loss': 6.3977813720703125}\n",
      "{'epoch': 0, 'batch': 207, 'loss': 6.069464683532715}\n",
      "{'epoch': 0, 'batch': 208, 'loss': 6.126399517059326}\n",
      "{'epoch': 0, 'batch': 209, 'loss': 6.535040855407715}\n",
      "{'epoch': 0, 'batch': 210, 'loss': 6.524895668029785}\n",
      "{'epoch': 0, 'batch': 211, 'loss': 6.635159969329834}\n",
      "{'epoch': 0, 'batch': 212, 'loss': 6.83380126953125}\n",
      "{'epoch': 0, 'batch': 213, 'loss': 6.823758602142334}\n",
      "{'epoch': 0, 'batch': 214, 'loss': 6.372542381286621}\n",
      "{'epoch': 0, 'batch': 215, 'loss': 6.718712329864502}\n",
      "{'epoch': 0, 'batch': 216, 'loss': 6.607702255249023}\n",
      "{'epoch': 0, 'batch': 217, 'loss': 6.164832592010498}\n",
      "{'epoch': 0, 'batch': 218, 'loss': 6.515448570251465}\n",
      "{'epoch': 0, 'batch': 219, 'loss': 6.776936054229736}\n",
      "{'epoch': 0, 'batch': 220, 'loss': 6.462315559387207}\n",
      "{'epoch': 0, 'batch': 221, 'loss': 8.123617172241211}\n",
      "{'epoch': 0, 'batch': 222, 'loss': 8.243110656738281}\n",
      "{'epoch': 0, 'batch': 223, 'loss': 5.9512224197387695}\n",
      "{'epoch': 0, 'batch': 224, 'loss': 6.318084239959717}\n",
      "{'epoch': 0, 'batch': 225, 'loss': 6.212466716766357}\n",
      "{'epoch': 0, 'batch': 226, 'loss': 6.421140670776367}\n",
      "{'epoch': 0, 'batch': 227, 'loss': 6.983940124511719}\n",
      "{'epoch': 0, 'batch': 228, 'loss': 7.760895729064941}\n",
      "{'epoch': 0, 'batch': 229, 'loss': 7.818626880645752}\n",
      "{'epoch': 0, 'batch': 230, 'loss': 6.954750061035156}\n",
      "{'epoch': 0, 'batch': 231, 'loss': 6.431818008422852}\n",
      "{'epoch': 0, 'batch': 232, 'loss': 6.275492191314697}\n",
      "{'epoch': 0, 'batch': 233, 'loss': 6.366511821746826}\n",
      "{'epoch': 0, 'batch': 234, 'loss': 6.588958263397217}\n",
      "{'epoch': 0, 'batch': 235, 'loss': 6.606582164764404}\n",
      "{'epoch': 0, 'batch': 236, 'loss': 6.081053256988525}\n",
      "{'epoch': 0, 'batch': 237, 'loss': 6.386441230773926}\n",
      "{'epoch': 0, 'batch': 238, 'loss': 6.912229061126709}\n",
      "{'epoch': 0, 'batch': 239, 'loss': 6.653071403503418}\n",
      "{'epoch': 0, 'batch': 240, 'loss': 6.390797138214111}\n",
      "{'epoch': 0, 'batch': 241, 'loss': 6.365039348602295}\n",
      "{'epoch': 0, 'batch': 242, 'loss': 6.2311906814575195}\n",
      "{'epoch': 0, 'batch': 243, 'loss': 6.525282382965088}\n",
      "{'epoch': 0, 'batch': 244, 'loss': 6.233404636383057}\n",
      "{'epoch': 0, 'batch': 245, 'loss': 6.8899006843566895}\n",
      "{'epoch': 0, 'batch': 246, 'loss': 6.707751750946045}\n",
      "{'epoch': 0, 'batch': 247, 'loss': 6.507922649383545}\n",
      "{'epoch': 0, 'batch': 248, 'loss': 6.140863418579102}\n",
      "{'epoch': 0, 'batch': 249, 'loss': 6.115209102630615}\n",
      "{'epoch': 0, 'batch': 250, 'loss': 5.931804180145264}\n",
      "{'epoch': 0, 'batch': 251, 'loss': 6.998251914978027}\n",
      "{'epoch': 0, 'batch': 252, 'loss': 6.731235027313232}\n",
      "{'epoch': 0, 'batch': 253, 'loss': 6.656968593597412}\n",
      "{'epoch': 0, 'batch': 254, 'loss': 6.177805423736572}\n",
      "{'epoch': 0, 'batch': 255, 'loss': 6.316995620727539}\n",
      "{'epoch': 0, 'batch': 256, 'loss': 6.32526969909668}\n",
      "{'epoch': 0, 'batch': 257, 'loss': 6.381237030029297}\n",
      "{'epoch': 0, 'batch': 258, 'loss': 6.307706832885742}\n",
      "{'epoch': 0, 'batch': 259, 'loss': 6.616631984710693}\n",
      "{'epoch': 0, 'batch': 260, 'loss': 6.778197288513184}\n",
      "{'epoch': 0, 'batch': 261, 'loss': 6.227741241455078}\n",
      "{'epoch': 0, 'batch': 262, 'loss': 6.114511489868164}\n",
      "{'epoch': 0, 'batch': 263, 'loss': 6.186919212341309}\n",
      "{'epoch': 0, 'batch': 264, 'loss': 6.6976823806762695}\n",
      "{'epoch': 0, 'batch': 265, 'loss': 6.4178853034973145}\n",
      "{'epoch': 0, 'batch': 266, 'loss': 6.363345146179199}\n",
      "{'epoch': 0, 'batch': 267, 'loss': 6.5277581214904785}\n",
      "{'epoch': 0, 'batch': 268, 'loss': 7.269847869873047}\n",
      "{'epoch': 0, 'batch': 269, 'loss': 7.832779884338379}\n",
      "{'epoch': 0, 'batch': 270, 'loss': 6.759076118469238}\n",
      "{'epoch': 0, 'batch': 271, 'loss': 6.425406455993652}\n",
      "{'epoch': 0, 'batch': 272, 'loss': 6.932641506195068}\n",
      "{'epoch': 0, 'batch': 273, 'loss': 6.246201038360596}\n",
      "{'epoch': 0, 'batch': 274, 'loss': 6.868340015411377}\n",
      "{'epoch': 0, 'batch': 275, 'loss': 6.404887676239014}\n",
      "{'epoch': 0, 'batch': 276, 'loss': 6.22080135345459}\n",
      "{'epoch': 0, 'batch': 277, 'loss': 6.4936628341674805}\n",
      "{'epoch': 0, 'batch': 278, 'loss': 6.373824119567871}\n",
      "{'epoch': 0, 'batch': 279, 'loss': 6.2823486328125}\n",
      "{'epoch': 0, 'batch': 280, 'loss': 6.282207489013672}\n",
      "{'epoch': 0, 'batch': 281, 'loss': 6.547044277191162}\n",
      "{'epoch': 0, 'batch': 282, 'loss': 6.055562973022461}\n",
      "{'epoch': 0, 'batch': 283, 'loss': 6.801632881164551}\n",
      "{'epoch': 0, 'batch': 284, 'loss': 6.523440837860107}\n",
      "{'epoch': 0, 'batch': 285, 'loss': 6.311999320983887}\n",
      "{'epoch': 0, 'batch': 286, 'loss': 6.383620262145996}\n",
      "{'epoch': 0, 'batch': 287, 'loss': 6.088667869567871}\n",
      "{'epoch': 0, 'batch': 288, 'loss': 5.7355217933654785}\n",
      "{'epoch': 0, 'batch': 289, 'loss': 6.13992977142334}\n",
      "{'epoch': 0, 'batch': 290, 'loss': 6.039746284484863}\n",
      "{'epoch': 0, 'batch': 291, 'loss': 6.671672344207764}\n",
      "{'epoch': 0, 'batch': 292, 'loss': 6.546904563903809}\n",
      "{'epoch': 0, 'batch': 293, 'loss': 6.235934734344482}\n",
      "{'epoch': 0, 'batch': 294, 'loss': 6.375899314880371}\n",
      "{'epoch': 0, 'batch': 295, 'loss': 6.218613624572754}\n",
      "{'epoch': 0, 'batch': 296, 'loss': 6.216592311859131}\n",
      "{'epoch': 0, 'batch': 297, 'loss': 6.344954490661621}\n",
      "{'epoch': 0, 'batch': 298, 'loss': 6.4252495765686035}\n",
      "{'epoch': 0, 'batch': 299, 'loss': 6.46734094619751}\n",
      "{'epoch': 0, 'batch': 300, 'loss': 6.455291748046875}\n",
      "{'epoch': 0, 'batch': 301, 'loss': 5.977201461791992}\n",
      "{'epoch': 0, 'batch': 302, 'loss': 6.367766380310059}\n",
      "{'epoch': 0, 'batch': 303, 'loss': 5.819955825805664}\n",
      "{'epoch': 0, 'batch': 304, 'loss': 6.568709373474121}\n",
      "{'epoch': 0, 'batch': 305, 'loss': 5.938405990600586}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 306, 'loss': 6.584113121032715}\n",
      "{'epoch': 0, 'batch': 307, 'loss': 6.231884956359863}\n",
      "{'epoch': 0, 'batch': 308, 'loss': 6.643652439117432}\n",
      "{'epoch': 0, 'batch': 309, 'loss': 6.418027877807617}\n",
      "{'epoch': 0, 'batch': 310, 'loss': 5.986758708953857}\n",
      "{'epoch': 0, 'batch': 311, 'loss': 6.269043445587158}\n",
      "{'epoch': 0, 'batch': 312, 'loss': 6.458680152893066}\n",
      "{'epoch': 0, 'batch': 313, 'loss': 6.354611873626709}\n",
      "{'epoch': 0, 'batch': 314, 'loss': 6.356424331665039}\n",
      "{'epoch': 0, 'batch': 315, 'loss': 6.019131660461426}\n",
      "{'epoch': 0, 'batch': 316, 'loss': 6.578962326049805}\n",
      "{'epoch': 0, 'batch': 317, 'loss': 6.37463903427124}\n",
      "{'epoch': 0, 'batch': 318, 'loss': 6.465153694152832}\n",
      "{'epoch': 0, 'batch': 319, 'loss': 6.514948844909668}\n",
      "{'epoch': 0, 'batch': 320, 'loss': 6.120205402374268}\n",
      "{'epoch': 0, 'batch': 321, 'loss': 6.135799884796143}\n",
      "{'epoch': 0, 'batch': 322, 'loss': 6.444023609161377}\n",
      "{'epoch': 0, 'batch': 323, 'loss': 7.186972141265869}\n",
      "{'epoch': 0, 'batch': 324, 'loss': 6.519092082977295}\n",
      "{'epoch': 0, 'batch': 325, 'loss': 6.224742412567139}\n",
      "{'epoch': 0, 'batch': 326, 'loss': 6.007092475891113}\n",
      "{'epoch': 0, 'batch': 327, 'loss': 6.166381359100342}\n",
      "{'epoch': 0, 'batch': 328, 'loss': 7.065742492675781}\n",
      "{'epoch': 0, 'batch': 329, 'loss': 6.618422985076904}\n",
      "{'epoch': 0, 'batch': 330, 'loss': 6.407024383544922}\n",
      "{'epoch': 0, 'batch': 331, 'loss': 6.509382724761963}\n",
      "{'epoch': 0, 'batch': 332, 'loss': 6.56993293762207}\n",
      "{'epoch': 0, 'batch': 333, 'loss': 6.033452033996582}\n",
      "{'epoch': 0, 'batch': 334, 'loss': 5.81982421875}\n",
      "{'epoch': 0, 'batch': 335, 'loss': 6.106163501739502}\n",
      "{'epoch': 0, 'batch': 336, 'loss': 5.942729473114014}\n",
      "{'epoch': 0, 'batch': 337, 'loss': 6.1408820152282715}\n",
      "{'epoch': 0, 'batch': 338, 'loss': 6.229050636291504}\n",
      "{'epoch': 0, 'batch': 339, 'loss': 6.077838897705078}\n",
      "{'epoch': 0, 'batch': 340, 'loss': 6.668416500091553}\n",
      "{'epoch': 0, 'batch': 341, 'loss': 6.2888078689575195}\n",
      "{'epoch': 0, 'batch': 342, 'loss': 5.917150497436523}\n",
      "{'epoch': 0, 'batch': 343, 'loss': 6.187489032745361}\n",
      "{'epoch': 0, 'batch': 344, 'loss': 6.427211284637451}\n",
      "{'epoch': 0, 'batch': 345, 'loss': 6.4482421875}\n",
      "{'epoch': 0, 'batch': 346, 'loss': 6.482302665710449}\n",
      "{'epoch': 0, 'batch': 347, 'loss': 6.304459571838379}\n",
      "{'epoch': 0, 'batch': 348, 'loss': 6.415204048156738}\n",
      "{'epoch': 0, 'batch': 349, 'loss': 6.618782043457031}\n",
      "{'epoch': 0, 'batch': 350, 'loss': 6.6636271476745605}\n",
      "{'epoch': 0, 'batch': 351, 'loss': 5.971258163452148}\n",
      "{'epoch': 0, 'batch': 352, 'loss': 6.412208080291748}\n",
      "{'epoch': 0, 'batch': 353, 'loss': 5.825570106506348}\n",
      "{'epoch': 0, 'batch': 354, 'loss': 5.691262722015381}\n",
      "{'epoch': 0, 'batch': 355, 'loss': 6.161264896392822}\n",
      "{'epoch': 0, 'batch': 356, 'loss': 6.044098377227783}\n",
      "{'epoch': 0, 'batch': 357, 'loss': 6.471157073974609}\n",
      "{'epoch': 0, 'batch': 358, 'loss': 6.367047309875488}\n",
      "{'epoch': 0, 'batch': 359, 'loss': 6.072882175445557}\n",
      "{'epoch': 0, 'batch': 360, 'loss': 6.285796642303467}\n",
      "{'epoch': 0, 'batch': 361, 'loss': 6.74654483795166}\n",
      "{'epoch': 0, 'batch': 362, 'loss': 6.301421165466309}\n",
      "{'epoch': 0, 'batch': 363, 'loss': 7.044239521026611}\n",
      "{'epoch': 0, 'batch': 364, 'loss': 6.752620220184326}\n",
      "{'epoch': 0, 'batch': 365, 'loss': 6.584823131561279}\n",
      "{'epoch': 0, 'batch': 366, 'loss': 6.9383673667907715}\n",
      "{'epoch': 0, 'batch': 367, 'loss': 6.095248699188232}\n",
      "{'epoch': 0, 'batch': 368, 'loss': 6.519554615020752}\n",
      "{'epoch': 0, 'batch': 369, 'loss': 6.3047990798950195}\n",
      "{'epoch': 0, 'batch': 370, 'loss': 6.488525867462158}\n",
      "{'epoch': 0, 'batch': 371, 'loss': 6.011163234710693}\n",
      "{'epoch': 0, 'batch': 372, 'loss': 7.076889991760254}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-3b2acfd1bc73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Add '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-87c61c9da689>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, model, results_list, batch, max_epochs, sequence_length)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mstate_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/Hackathons/Bon-Hacketit/venv/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/Hackathons/Bon-Hacketit/venv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = Dataset(train_df)\n",
    "model = Model(dataset)\n",
    "results = []\n",
    "\n",
    "train(dataset, model, results)\n",
    "print(predict(dataset, model, text='Add '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bon-Hacketit",
   "language": "python",
   "name": "bon-hacketit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
