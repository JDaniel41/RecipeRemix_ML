{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = 128\n",
    "        self.embedding_dim = 128\n",
    "        self.num_layers = 3\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df\n",
    "    ):\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "    def load_words(self):\n",
    "        text = train_df.str.cat(sep=' ')\n",
    "        return text.split(' ')\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - 4\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+4]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+4+1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model, results_list, batch_s=256, max_epochs=10, sequence_length=4):\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_s)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        state_h, state_c = model.init_state(sequence_length)\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
    "            results_list.append([epoch, batch, loss.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model, text, next_words=100):\n",
    "    model.eval()\n",
    "\n",
    "    words = text.split(' ')\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmdanie/Documents/Code/Hackathons/Bon-Hacketit/venv/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/RAW_recipes.csv')\n",
    "recipe_df = df[[\"steps\"]]\n",
    "\n",
    "recipe_df[\"processed\"] = [\". \".join(ast.literal_eval(step_array)) for step_array in recipe_df.steps]\n",
    "\n",
    "train_df, test_df = train_test_split(recipe_df[\"processed\"], train_size=.8, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 0, 'loss': 11.242292404174805}\n",
      "{'epoch': 0, 'batch': 1, 'loss': 11.238499641418457}\n",
      "{'epoch': 0, 'batch': 2, 'loss': 11.226659774780273}\n",
      "{'epoch': 0, 'batch': 3, 'loss': 11.217924118041992}\n",
      "{'epoch': 0, 'batch': 4, 'loss': 11.214835166931152}\n",
      "{'epoch': 0, 'batch': 5, 'loss': 11.191398620605469}\n",
      "{'epoch': 0, 'batch': 6, 'loss': 11.167433738708496}\n",
      "{'epoch': 0, 'batch': 7, 'loss': 11.154248237609863}\n",
      "{'epoch': 0, 'batch': 8, 'loss': 11.054868698120117}\n",
      "{'epoch': 0, 'batch': 9, 'loss': 10.949844360351562}\n",
      "{'epoch': 0, 'batch': 10, 'loss': 10.803844451904297}\n",
      "{'epoch': 0, 'batch': 11, 'loss': 10.574508666992188}\n",
      "{'epoch': 0, 'batch': 12, 'loss': 10.424949645996094}\n",
      "{'epoch': 0, 'batch': 13, 'loss': 10.010403633117676}\n",
      "{'epoch': 0, 'batch': 14, 'loss': 9.888875961303711}\n",
      "{'epoch': 0, 'batch': 15, 'loss': 9.780108451843262}\n",
      "{'epoch': 0, 'batch': 16, 'loss': 9.644513130187988}\n",
      "{'epoch': 0, 'batch': 17, 'loss': 9.052526473999023}\n",
      "{'epoch': 0, 'batch': 18, 'loss': 8.927183151245117}\n",
      "{'epoch': 0, 'batch': 19, 'loss': 8.519811630249023}\n",
      "{'epoch': 0, 'batch': 20, 'loss': 8.490036010742188}\n",
      "{'epoch': 0, 'batch': 21, 'loss': 8.563058853149414}\n",
      "{'epoch': 0, 'batch': 22, 'loss': 8.122466087341309}\n",
      "{'epoch': 0, 'batch': 23, 'loss': 8.1658296585083}\n",
      "{'epoch': 0, 'batch': 24, 'loss': 8.110784530639648}\n",
      "{'epoch': 0, 'batch': 25, 'loss': 7.774776935577393}\n",
      "{'epoch': 0, 'batch': 26, 'loss': 7.4619140625}\n",
      "{'epoch': 0, 'batch': 27, 'loss': 7.224430084228516}\n",
      "{'epoch': 0, 'batch': 28, 'loss': 7.2677741050720215}\n",
      "{'epoch': 0, 'batch': 29, 'loss': 6.850895881652832}\n",
      "{'epoch': 0, 'batch': 30, 'loss': 6.879488945007324}\n",
      "{'epoch': 0, 'batch': 31, 'loss': 6.677523136138916}\n",
      "{'epoch': 0, 'batch': 32, 'loss': 7.1357574462890625}\n",
      "{'epoch': 0, 'batch': 33, 'loss': 6.780827522277832}\n",
      "{'epoch': 0, 'batch': 34, 'loss': 6.521659851074219}\n",
      "{'epoch': 0, 'batch': 35, 'loss': 6.8423614501953125}\n",
      "{'epoch': 0, 'batch': 36, 'loss': 6.407353401184082}\n",
      "{'epoch': 0, 'batch': 37, 'loss': 6.379481315612793}\n",
      "{'epoch': 0, 'batch': 38, 'loss': 6.553150177001953}\n",
      "{'epoch': 0, 'batch': 39, 'loss': 6.7288055419921875}\n",
      "{'epoch': 0, 'batch': 40, 'loss': 6.839831352233887}\n",
      "{'epoch': 0, 'batch': 41, 'loss': 6.194309711456299}\n",
      "{'epoch': 0, 'batch': 42, 'loss': 6.66316556930542}\n",
      "{'epoch': 0, 'batch': 43, 'loss': 7.183265209197998}\n",
      "{'epoch': 0, 'batch': 44, 'loss': 6.719433307647705}\n",
      "{'epoch': 0, 'batch': 45, 'loss': 6.538224697113037}\n",
      "{'epoch': 0, 'batch': 46, 'loss': 6.897965431213379}\n",
      "{'epoch': 0, 'batch': 47, 'loss': 6.630654811859131}\n",
      "{'epoch': 0, 'batch': 48, 'loss': 6.876407623291016}\n",
      "{'epoch': 0, 'batch': 49, 'loss': 6.557308673858643}\n",
      "{'epoch': 0, 'batch': 50, 'loss': 6.546654224395752}\n",
      "{'epoch': 0, 'batch': 51, 'loss': 6.5686354637146}\n",
      "{'epoch': 0, 'batch': 52, 'loss': 6.13360595703125}\n",
      "{'epoch': 0, 'batch': 53, 'loss': 6.698676586151123}\n",
      "{'epoch': 0, 'batch': 54, 'loss': 6.191722393035889}\n",
      "{'epoch': 0, 'batch': 55, 'loss': 7.188635349273682}\n",
      "{'epoch': 0, 'batch': 56, 'loss': 6.250641822814941}\n",
      "{'epoch': 0, 'batch': 57, 'loss': 6.4103593826293945}\n",
      "{'epoch': 0, 'batch': 58, 'loss': 5.948740482330322}\n",
      "{'epoch': 0, 'batch': 59, 'loss': 6.559560298919678}\n",
      "{'epoch': 0, 'batch': 60, 'loss': 6.2402567863464355}\n",
      "{'epoch': 0, 'batch': 61, 'loss': 6.5818634033203125}\n",
      "{'epoch': 0, 'batch': 62, 'loss': 5.812211513519287}\n",
      "{'epoch': 0, 'batch': 63, 'loss': 6.045506000518799}\n",
      "{'epoch': 0, 'batch': 64, 'loss': 6.938633441925049}\n",
      "{'epoch': 0, 'batch': 65, 'loss': 6.225840091705322}\n",
      "{'epoch': 0, 'batch': 66, 'loss': 7.037181377410889}\n",
      "{'epoch': 0, 'batch': 67, 'loss': 7.347797870635986}\n",
      "{'epoch': 0, 'batch': 68, 'loss': 6.882165908813477}\n",
      "{'epoch': 0, 'batch': 69, 'loss': 6.6582560539245605}\n",
      "{'epoch': 0, 'batch': 70, 'loss': 6.82295036315918}\n",
      "{'epoch': 0, 'batch': 71, 'loss': 6.507547378540039}\n",
      "{'epoch': 0, 'batch': 72, 'loss': 6.121076583862305}\n",
      "{'epoch': 0, 'batch': 73, 'loss': 6.4443464279174805}\n",
      "{'epoch': 0, 'batch': 74, 'loss': 6.756431579589844}\n",
      "{'epoch': 0, 'batch': 75, 'loss': 7.03602933883667}\n",
      "{'epoch': 0, 'batch': 76, 'loss': 6.432121276855469}\n",
      "{'epoch': 0, 'batch': 77, 'loss': 6.417128562927246}\n",
      "{'epoch': 0, 'batch': 78, 'loss': 6.466935157775879}\n",
      "{'epoch': 0, 'batch': 79, 'loss': 6.654118537902832}\n",
      "{'epoch': 0, 'batch': 80, 'loss': 7.040652275085449}\n",
      "{'epoch': 0, 'batch': 81, 'loss': 6.901688575744629}\n",
      "{'epoch': 0, 'batch': 82, 'loss': 6.706733226776123}\n",
      "{'epoch': 0, 'batch': 83, 'loss': 6.174973487854004}\n",
      "{'epoch': 0, 'batch': 84, 'loss': 6.646054267883301}\n",
      "{'epoch': 0, 'batch': 85, 'loss': 6.580600738525391}\n",
      "{'epoch': 0, 'batch': 86, 'loss': 6.3006696701049805}\n",
      "{'epoch': 0, 'batch': 87, 'loss': 6.805784702301025}\n",
      "{'epoch': 0, 'batch': 88, 'loss': 6.892541408538818}\n",
      "{'epoch': 0, 'batch': 89, 'loss': 7.227000713348389}\n",
      "{'epoch': 0, 'batch': 90, 'loss': 6.7905497550964355}\n",
      "{'epoch': 0, 'batch': 91, 'loss': 7.074120998382568}\n",
      "{'epoch': 0, 'batch': 92, 'loss': 6.812229633331299}\n",
      "{'epoch': 0, 'batch': 93, 'loss': 6.5568132400512695}\n",
      "{'epoch': 0, 'batch': 94, 'loss': 6.462577819824219}\n",
      "{'epoch': 0, 'batch': 95, 'loss': 5.87123441696167}\n",
      "{'epoch': 0, 'batch': 96, 'loss': 6.13016414642334}\n",
      "{'epoch': 0, 'batch': 97, 'loss': 6.344946384429932}\n",
      "{'epoch': 0, 'batch': 98, 'loss': 6.762593746185303}\n",
      "{'epoch': 0, 'batch': 99, 'loss': 6.447943210601807}\n",
      "{'epoch': 0, 'batch': 100, 'loss': 6.597334861755371}\n",
      "{'epoch': 0, 'batch': 101, 'loss': 6.950704574584961}\n",
      "{'epoch': 0, 'batch': 102, 'loss': 5.929340362548828}\n",
      "{'epoch': 0, 'batch': 103, 'loss': 6.757503509521484}\n",
      "{'epoch': 0, 'batch': 104, 'loss': 6.697603702545166}\n",
      "{'epoch': 0, 'batch': 105, 'loss': 6.113633155822754}\n",
      "{'epoch': 0, 'batch': 106, 'loss': 6.00672721862793}\n",
      "{'epoch': 0, 'batch': 107, 'loss': 6.404730319976807}\n",
      "{'epoch': 0, 'batch': 108, 'loss': 6.228799343109131}\n",
      "{'epoch': 0, 'batch': 109, 'loss': 6.83516788482666}\n",
      "{'epoch': 0, 'batch': 110, 'loss': 5.66042947769165}\n",
      "{'epoch': 0, 'batch': 111, 'loss': 6.548623561859131}\n",
      "{'epoch': 0, 'batch': 112, 'loss': 6.196735382080078}\n",
      "{'epoch': 0, 'batch': 113, 'loss': 7.60746955871582}\n",
      "{'epoch': 0, 'batch': 114, 'loss': 6.047569274902344}\n",
      "{'epoch': 0, 'batch': 115, 'loss': 6.437332630157471}\n",
      "{'epoch': 0, 'batch': 116, 'loss': 6.063047409057617}\n",
      "{'epoch': 0, 'batch': 117, 'loss': 6.681488513946533}\n",
      "{'epoch': 0, 'batch': 118, 'loss': 6.3078765869140625}\n",
      "{'epoch': 0, 'batch': 119, 'loss': 6.356778621673584}\n",
      "{'epoch': 0, 'batch': 120, 'loss': 6.296475410461426}\n",
      "{'epoch': 0, 'batch': 121, 'loss': 6.40166711807251}\n",
      "{'epoch': 0, 'batch': 122, 'loss': 6.7796950340271}\n",
      "{'epoch': 0, 'batch': 123, 'loss': 6.838547706604004}\n",
      "{'epoch': 0, 'batch': 124, 'loss': 6.666528701782227}\n",
      "{'epoch': 0, 'batch': 125, 'loss': 6.4639482498168945}\n",
      "{'epoch': 0, 'batch': 126, 'loss': 6.538880825042725}\n",
      "{'epoch': 0, 'batch': 127, 'loss': 6.5750732421875}\n",
      "{'epoch': 0, 'batch': 128, 'loss': 6.252368450164795}\n",
      "{'epoch': 0, 'batch': 129, 'loss': 5.908669471740723}\n",
      "{'epoch': 0, 'batch': 130, 'loss': 6.734865188598633}\n",
      "{'epoch': 0, 'batch': 131, 'loss': 6.117031574249268}\n",
      "{'epoch': 0, 'batch': 132, 'loss': 6.39964485168457}\n",
      "{'epoch': 0, 'batch': 133, 'loss': 6.074941158294678}\n",
      "{'epoch': 0, 'batch': 134, 'loss': 6.513481616973877}\n",
      "{'epoch': 0, 'batch': 135, 'loss': 6.296823501586914}\n",
      "{'epoch': 0, 'batch': 136, 'loss': 6.0305681228637695}\n",
      "{'epoch': 0, 'batch': 137, 'loss': 6.604945182800293}\n",
      "{'epoch': 0, 'batch': 138, 'loss': 6.705151081085205}\n",
      "{'epoch': 0, 'batch': 139, 'loss': 6.324712753295898}\n",
      "{'epoch': 0, 'batch': 140, 'loss': 6.882030963897705}\n",
      "{'epoch': 0, 'batch': 141, 'loss': 6.533919334411621}\n",
      "{'epoch': 0, 'batch': 142, 'loss': 6.010823726654053}\n",
      "{'epoch': 0, 'batch': 143, 'loss': 6.681319236755371}\n",
      "{'epoch': 0, 'batch': 144, 'loss': 6.638480186462402}\n",
      "{'epoch': 0, 'batch': 145, 'loss': 6.59505558013916}\n",
      "{'epoch': 0, 'batch': 146, 'loss': 6.4633564949035645}\n",
      "{'epoch': 0, 'batch': 147, 'loss': 5.9329142570495605}\n",
      "{'epoch': 0, 'batch': 148, 'loss': 7.11443567276001}\n",
      "{'epoch': 0, 'batch': 149, 'loss': 6.563113689422607}\n",
      "{'epoch': 0, 'batch': 150, 'loss': 6.31674861907959}\n",
      "{'epoch': 0, 'batch': 151, 'loss': 6.477497100830078}\n",
      "{'epoch': 0, 'batch': 152, 'loss': 6.486669540405273}\n",
      "{'epoch': 0, 'batch': 153, 'loss': 6.0626678466796875}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 154, 'loss': 7.084575653076172}\n",
      "{'epoch': 0, 'batch': 155, 'loss': 6.848651885986328}\n",
      "{'epoch': 0, 'batch': 156, 'loss': 6.781240463256836}\n",
      "{'epoch': 0, 'batch': 157, 'loss': 6.283814907073975}\n",
      "{'epoch': 0, 'batch': 158, 'loss': 6.34154748916626}\n",
      "{'epoch': 0, 'batch': 159, 'loss': 7.044858932495117}\n",
      "{'epoch': 0, 'batch': 160, 'loss': 6.322938442230225}\n",
      "{'epoch': 0, 'batch': 161, 'loss': 6.229717254638672}\n",
      "{'epoch': 0, 'batch': 162, 'loss': 6.4532999992370605}\n",
      "{'epoch': 0, 'batch': 163, 'loss': 6.341999530792236}\n",
      "{'epoch': 0, 'batch': 164, 'loss': 6.28667688369751}\n",
      "{'epoch': 0, 'batch': 165, 'loss': 6.280598163604736}\n",
      "{'epoch': 0, 'batch': 166, 'loss': 5.97722864151001}\n",
      "{'epoch': 0, 'batch': 167, 'loss': 6.877725601196289}\n",
      "{'epoch': 0, 'batch': 168, 'loss': 6.231250762939453}\n",
      "{'epoch': 0, 'batch': 169, 'loss': 6.182936191558838}\n",
      "{'epoch': 0, 'batch': 170, 'loss': 6.239219665527344}\n",
      "{'epoch': 0, 'batch': 171, 'loss': 6.64828634262085}\n",
      "{'epoch': 0, 'batch': 172, 'loss': 6.6518049240112305}\n",
      "{'epoch': 0, 'batch': 173, 'loss': 6.3637590408325195}\n",
      "{'epoch': 0, 'batch': 174, 'loss': 6.601751804351807}\n",
      "{'epoch': 0, 'batch': 175, 'loss': 6.496793270111084}\n",
      "{'epoch': 0, 'batch': 176, 'loss': 6.366950988769531}\n",
      "{'epoch': 0, 'batch': 177, 'loss': 6.236110210418701}\n",
      "{'epoch': 0, 'batch': 178, 'loss': 6.293017387390137}\n",
      "{'epoch': 0, 'batch': 179, 'loss': 6.4998369216918945}\n",
      "{'epoch': 0, 'batch': 180, 'loss': 6.837777137756348}\n",
      "{'epoch': 0, 'batch': 181, 'loss': 6.493734359741211}\n",
      "{'epoch': 0, 'batch': 182, 'loss': 6.089583396911621}\n",
      "{'epoch': 0, 'batch': 183, 'loss': 6.867733001708984}\n",
      "{'epoch': 0, 'batch': 184, 'loss': 6.348100185394287}\n",
      "{'epoch': 0, 'batch': 185, 'loss': 6.339958190917969}\n",
      "{'epoch': 0, 'batch': 186, 'loss': 6.6879682540893555}\n",
      "{'epoch': 0, 'batch': 187, 'loss': 6.205563068389893}\n",
      "{'epoch': 0, 'batch': 188, 'loss': 6.173181533813477}\n",
      "{'epoch': 0, 'batch': 189, 'loss': 5.8875250816345215}\n",
      "{'epoch': 0, 'batch': 190, 'loss': 6.0162858963012695}\n",
      "{'epoch': 0, 'batch': 191, 'loss': 6.412792205810547}\n",
      "{'epoch': 0, 'batch': 192, 'loss': 6.617902755737305}\n",
      "{'epoch': 0, 'batch': 193, 'loss': 6.525747299194336}\n",
      "{'epoch': 0, 'batch': 194, 'loss': 6.857620716094971}\n",
      "{'epoch': 0, 'batch': 195, 'loss': 6.439085483551025}\n",
      "{'epoch': 0, 'batch': 196, 'loss': 6.620090961456299}\n",
      "{'epoch': 0, 'batch': 197, 'loss': 6.511106967926025}\n",
      "{'epoch': 0, 'batch': 198, 'loss': 6.612264633178711}\n",
      "{'epoch': 0, 'batch': 199, 'loss': 6.0939459800720215}\n",
      "{'epoch': 0, 'batch': 200, 'loss': 6.456364631652832}\n",
      "{'epoch': 0, 'batch': 201, 'loss': 6.104879379272461}\n",
      "{'epoch': 0, 'batch': 202, 'loss': 6.250516891479492}\n",
      "{'epoch': 0, 'batch': 203, 'loss': 6.8095221519470215}\n",
      "{'epoch': 0, 'batch': 204, 'loss': 6.50065279006958}\n",
      "{'epoch': 0, 'batch': 205, 'loss': 6.594265937805176}\n",
      "{'epoch': 0, 'batch': 206, 'loss': 6.4381842613220215}\n",
      "{'epoch': 0, 'batch': 207, 'loss': 6.063873291015625}\n",
      "{'epoch': 0, 'batch': 208, 'loss': 6.117477893829346}\n",
      "{'epoch': 0, 'batch': 209, 'loss': 6.561093807220459}\n",
      "{'epoch': 0, 'batch': 210, 'loss': 6.527866840362549}\n",
      "{'epoch': 0, 'batch': 211, 'loss': 6.641482353210449}\n",
      "{'epoch': 0, 'batch': 212, 'loss': 6.841799259185791}\n",
      "{'epoch': 0, 'batch': 213, 'loss': 6.818940162658691}\n",
      "{'epoch': 0, 'batch': 214, 'loss': 6.374660491943359}\n",
      "{'epoch': 0, 'batch': 215, 'loss': 6.720181465148926}\n",
      "{'epoch': 0, 'batch': 216, 'loss': 6.607344150543213}\n",
      "{'epoch': 0, 'batch': 217, 'loss': 6.178671836853027}\n",
      "{'epoch': 0, 'batch': 218, 'loss': 6.500682353973389}\n",
      "{'epoch': 0, 'batch': 219, 'loss': 6.784523963928223}\n",
      "{'epoch': 0, 'batch': 220, 'loss': 6.479231834411621}\n",
      "{'epoch': 0, 'batch': 221, 'loss': 8.147964477539062}\n",
      "{'epoch': 0, 'batch': 222, 'loss': 8.266032218933105}\n",
      "{'epoch': 0, 'batch': 223, 'loss': 5.968354225158691}\n",
      "{'epoch': 0, 'batch': 224, 'loss': 6.338897228240967}\n",
      "{'epoch': 0, 'batch': 225, 'loss': 6.2119646072387695}\n",
      "{'epoch': 0, 'batch': 226, 'loss': 6.422709941864014}\n",
      "{'epoch': 0, 'batch': 227, 'loss': 7.002333641052246}\n",
      "{'epoch': 0, 'batch': 228, 'loss': 7.795677661895752}\n",
      "{'epoch': 0, 'batch': 229, 'loss': 7.828518867492676}\n",
      "{'epoch': 0, 'batch': 230, 'loss': 6.96429967880249}\n",
      "{'epoch': 0, 'batch': 231, 'loss': 6.424321174621582}\n",
      "{'epoch': 0, 'batch': 232, 'loss': 6.287998199462891}\n",
      "{'epoch': 0, 'batch': 233, 'loss': 6.388880729675293}\n",
      "{'epoch': 0, 'batch': 234, 'loss': 6.598034858703613}\n",
      "{'epoch': 0, 'batch': 235, 'loss': 6.6140828132629395}\n",
      "{'epoch': 0, 'batch': 236, 'loss': 6.095183849334717}\n",
      "{'epoch': 0, 'batch': 237, 'loss': 6.399689197540283}\n",
      "{'epoch': 0, 'batch': 238, 'loss': 6.923897743225098}\n",
      "{'epoch': 0, 'batch': 239, 'loss': 6.656626224517822}\n",
      "{'epoch': 0, 'batch': 240, 'loss': 6.391308307647705}\n",
      "{'epoch': 0, 'batch': 241, 'loss': 6.349803924560547}\n",
      "{'epoch': 0, 'batch': 242, 'loss': 6.2373738288879395}\n",
      "{'epoch': 0, 'batch': 243, 'loss': 6.519819736480713}\n",
      "{'epoch': 0, 'batch': 244, 'loss': 6.242898941040039}\n",
      "{'epoch': 0, 'batch': 245, 'loss': 6.88928747177124}\n",
      "{'epoch': 0, 'batch': 246, 'loss': 6.719915866851807}\n",
      "{'epoch': 0, 'batch': 247, 'loss': 6.502735614776611}\n",
      "{'epoch': 0, 'batch': 248, 'loss': 6.131242275238037}\n",
      "{'epoch': 0, 'batch': 249, 'loss': 6.123959064483643}\n",
      "{'epoch': 0, 'batch': 250, 'loss': 5.927484035491943}\n",
      "{'epoch': 0, 'batch': 251, 'loss': 6.988103866577148}\n",
      "{'epoch': 0, 'batch': 252, 'loss': 6.752745151519775}\n",
      "{'epoch': 0, 'batch': 253, 'loss': 6.660683631896973}\n",
      "{'epoch': 0, 'batch': 254, 'loss': 6.192999362945557}\n",
      "{'epoch': 0, 'batch': 255, 'loss': 6.326531887054443}\n",
      "{'epoch': 0, 'batch': 256, 'loss': 6.307231903076172}\n",
      "{'epoch': 0, 'batch': 257, 'loss': 6.390803813934326}\n",
      "{'epoch': 0, 'batch': 258, 'loss': 6.302164554595947}\n",
      "{'epoch': 0, 'batch': 259, 'loss': 6.599196434020996}\n",
      "{'epoch': 0, 'batch': 260, 'loss': 6.770355224609375}\n",
      "{'epoch': 0, 'batch': 261, 'loss': 6.222554683685303}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-3b2acfd1bc73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Add '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-eb4c8b0aaf09>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, model, results_list, batch_s, max_epochs, sequence_length)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mstate_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/Hackathons/Bon-Hacketit/venv/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Code/Hackathons/Bon-Hacketit/venv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = Dataset(train_df)\n",
    "model = Model(dataset)\n",
    "results = []\n",
    "\n",
    "train(dataset, model, results)\n",
    "print(predict(dataset, model, text='Add '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bon-Hacketit",
   "language": "python",
   "name": "bon-hacketit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
